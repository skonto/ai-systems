FROM  ollama/ollama

ARG MODELS="mxbai-embed-large llama3:instruct"

ENV OLLAMA_KEEP_ALIVE=24h

RUN ollama serve & server=$! ; sleep 5 ; for m in $MODELS ; do ollama pull $m ; done ; kill $server

ENV OLLAMA_HOST=0.0.0.0:8080

ENTRYPOINT ["/bin/ollama"]

CMD ["serve"]